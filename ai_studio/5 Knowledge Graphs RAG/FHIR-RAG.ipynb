{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with FHIR data Powered by Knowledge Graphs on FHIR data\n",
    "\n",
    "While finetuning and RAG are powerful methods to adapt pre-trained AI models like llama3, they don't take advantage of the underlying connectedness of the data. In healthcare, R&D, and all knowledge oriented fields there is an inhererent connected-ness in the data. \n",
    "\n",
    "Here we explore the use of Knowledge Graphs as an augmented RAG approach to retrieve data about blood pressure. Now obviously, the model without any reference isn't able to give a good answer, but with the KG augmented RAG input it returns the right answer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The data for the patient I used for this notebook came from [Synthea](https://synthea.mitre.org/) which generates aritificial FHIR data for synthetic patients. \n",
    "\n",
    "#### Special Thanks To\n",
    "This work has been heavily inspired by work done by [Sam Schifman ](https://medium.com/@samschifman/rag-on-fhir-29a9771f49b6). Much of the underlying code to read and parse FHIR data is from him and has *not* been included here. \n",
    "Neo4J has some excellent talks about the topic of using KGs with RAG: [Neo4J Going Meta talks](https://github.com/jbarrasa/goingmeta/tree/main),  [Session 23: Advanced RAG patterns with Knowledge Graphs](https://www.youtube.com/watch?v=E_JO4-2D5Xs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Imports from other local python files\n",
    "from NEO4J_Graph import Graph\n",
    "from FHIR_to_graph import resource_to_node, resource_to_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\" #os.getenv('FHIR_GRAPH_URL')\n",
    "USERNAME = \"neo4j\" #os.getenv('FHIR_GRAPH_USER')\n",
    "PASSWORD = \"fhir_pass\" #os.getenv('FHIR_GRAPH_PASSWORD')\n",
    "DATABASE = \"neo4j\" #os.getenv('FHIR_GRAPH_DATABASE')\n",
    "\n",
    "graph = Graph(NEO4J_URI, USERNAME, PASSWORD, DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the FHIR data into the graph format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthea_bundles = glob.glob(\"../../FHIR Data/use_data/*.json\")\n",
    "synthea_bundles.sort()\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "dates = set() # set is used here to make sure dates are unique\n",
    "for bundle_file_name in synthea_bundles:\n",
    "    with open(bundle_file_name) as raw:\n",
    "        bundle = json.load(raw)\n",
    "        for entry in bundle['entry']:\n",
    "            resource_type = entry['resource']['resourceType']\n",
    "            if resource_type != 'Provenance':\n",
    "                # generated the cypher for creating the resource node \n",
    "                nodes.append(resource_to_node(entry['resource']))\n",
    "                # generated the cypher for creating the reference & date edges and capture dates\n",
    "                node_edges, node_dates = resource_to_edges(entry['resource'])\n",
    "                edges += node_edges\n",
    "                dates.update(node_dates)\n",
    "\n",
    "# create the nodes for resources\n",
    "for node in nodes:\n",
    "    graph.query(node)\n",
    "\n",
    "\n",
    "date_pattern = re.compile(r'([0-9]+)/([0-9]+)/([0-9]+)')\n",
    "\n",
    "# create the nodes for dates\n",
    "for date in dates:\n",
    "    date_parts = date_pattern.findall(date)[0]\n",
    "    cypher_date = f'{date_parts[2]}-{date_parts[0]}-{date_parts[1]}'\n",
    "    cypher = 'CREATE (:Date {name:\"' + date + '\", id: \"' + date + '\", date: date(\"' + cypher_date + '\")})'\n",
    "    graph.query(cypher)\n",
    "\n",
    "# create the edges\n",
    "for edge in edges:\n",
    "    try:\n",
    "        graph.query(edge)\n",
    "    except:\n",
    "        print(f'Failed to create edge: {edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Patient', 1], ['Device', 2], ['CarePlan', 7], ['CareTeam', 7], ['Immunization', 12], ['MedicationRequest', 19], ['SupplyDelivery', 20], ['Condition', 46], ['Procedure', 104], ['DocumentReference', 106], ['Encounter', 106], ['Claim', 125], ['ExplanationOfBenefit', 125], ['DiagnosticReport', 167], ['Observation', 542]]\n"
     ]
    }
   ],
   "source": [
    "# print out some information to show that the graph is populated.\n",
    "print(graph.resource_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vector Embedding Index in the Graph\n",
    "\n",
    "This cell creates a Vector Index in Neo4J. It looks at nodes labeled as `resource` and indexes the string representation in the `text` property. \n",
    "\n",
    "**Warning:** This cell may take sometime to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neo4jVector.from_existing_graph(\n",
    "    HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    url=NEO4J_URI,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    database=DATABASE,\n",
    "    index_name='fhir_text',\n",
    "    node_label=\"resource\",\n",
    "    text_node_properties=['text'],\n",
    "    embedding_node_property='embedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Index \n",
    "\n",
    "This cell creates a new vector index, using the index created above. \n",
    "\n",
    "This is here because running the cell above can take time and only should be done one time when the DB is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Neo4jVector.from_existing_index(\n",
    "    HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    url=NEO4J_URI,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    database=DATABASE,\n",
    "    index_name='fhir_text'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Prompt Templates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "in_prompt='''\n",
    "System: The context below contains entries about the patient's healthcare. \n",
    "Please limit your answer to the information provided in the context. Do not make up facts. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "If you are asked about the patient's name and one the entries is of type patient, you should look for the first given name and family name and answer with: [given] [family]\n",
    "----------------\n",
    "{context}\n",
    "Human: {question}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(in_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the LLM model to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = 'llama3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask the question to AI with and without KG-RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the blood pressure?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of blood pressure in our previous conversation. We only discussed the topic of \"what's on your mind?\" and I provided some suggestions to help you clarify your thoughts. If you'd like to discuss something specific, such as blood pressure or any other health-related topics, I'm here to listen and provide general information. However, please note that I am not a medical professional, and it's always best to consult with a healthcare expert for personalized advice.\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=ollama_model)\n",
    "no_rag_answer = llm(question)\n",
    "print(no_rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of information in this entry is observation. The status for this observation is final. The category of this observation is Vital signs. The code for this observation is Blood pressure panel with all children optional. This observation was effective date time on 02/09/2014 at 11:51:24. This observation was issued on 02/09/2014 at 11:51:24. This observation contains 2 components. The 1st component's code for this observation is Diastolic Blood Pressure. The 1st component's value quantity for this observation is 88 mm[Hg]. The 2nd component's code for this observation is Systolic Blood Pressure. The 2nd component's value quantity for this observation is 133 mm[Hg].\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "response = vector_index.similarity_search(question)#, k=2) \n",
    "print(response[0].page_content)\n",
    "print(len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "System: The context below contains entries about the patient's healthcare. \n",
      "Please limit your answer to the information provided in the context. Do not make up facts. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "If you are asked about the patient's name and one the entries is of type patient, you should look for the first given name and family name and answer with: [given] [family]\n",
      "----------------\n",
      "The type of information in this entry is observation. The status for this observation is final. The category of this observation is Vital signs. The code for this observation is Blood pressure panel with all children optional. This observation was effective date time on 02/09/2014 at 11:51:24. This observation was issued on 02/09/2014 at 11:51:24. This observation contains 2 components. The 1st component's code for this observation is Diastolic Blood Pressure. The 1st component's value quantity for this observation is 88 mm[Hg]. The 2nd component's code for this observation is Systolic Blood Pressure. The 2nd component's value quantity for this observation is 133 mm[Hg].\n",
      "\n",
      "The type of information in this entry is observation. The status for this observation is final. The category of this observation is Vital signs. The code for this observation is Blood pressure panel with all children optional. This observation was effective date time on 08/30/2023 at 11:51:24. This observation was issued on 08/30/2023 at 11:51:24. This observation contains 2 components. The 1st component's code for this observation is Diastolic Blood Pressure. The 1st component's value quantity for this observation is 99 mm[Hg]. The 2nd component's code for this observation is Systolic Blood Pressure. The 2nd component's value quantity for this observation is 140 mm[Hg].\n",
      "Human: What was the blood pressure?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(\"According to the observations, the patient's blood pressure components are:\\n\"\n",
      " '\\n'\n",
      " '* Diastolic Blood Pressure: 88 mm[Hg] (02/09/2014) and 99 mm[Hg] '\n",
      " '(08/30/2023)\\n'\n",
      " '* Systolic Blood Pressure: 133 mm[Hg] (02/09/2014) and 140 mm[Hg] '\n",
      " '(08/30/2023)\\n'\n",
      " '\\n'\n",
      " 'So, the blood pressure is:\\n'\n",
      " '\\n'\n",
      " '* Diastolic: 88-99 mm[Hg]\\n'\n",
      " '* Systolic: 133-140 mm[Hg]')\n"
     ]
    }
   ],
   "source": [
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOllama(model=ollama_model), chain_type=\"stuff\", retriever=vector_index.as_retriever(search_kwargs={'k': 2}), \n",
    "    verbose=True, chain_type_kwargs={\"verbose\": True, \"prompt\": prompt}\n",
    ")\n",
    "\n",
    "pprint(vector_qa.run(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knolgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
